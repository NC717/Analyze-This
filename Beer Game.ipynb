{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction for beer score (Machine Learning Hack competition)\n",
    "This notebook contains the solution for Machine learning hack competition for predicting the beer score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pyensembler import ensembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(r'F:\\Hackathons_Codes_and_Data\\Machine_Learning_Hack\\How-To-Choose-The-Perfect-Beer-Data-Set\\Beer Train Data Set.csv')\n",
    "test_data = pd.read_csv(r'F:\\Hackathons_Codes_and_Data\\Machine_Learning_Hack\\How-To-Choose-The-Perfect-Beer-Data-Set\\Beer Test Data Set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesing for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = train_data._get_numeric_data()\n",
    "char = train_data.select_dtypes(include = ['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(char.isnull().sum())\n",
    "print(num.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing the - from serving and cellar temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\nilu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\nilu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "char['Serving'] = char['Serving Temperature'].str.split('-', expand =True).astype(float).mean(axis=1)\n",
    "char['Cellar'] = char['Cellar Temperature'].str.split('-', expand =True).astype(float).mean(axis= 1)\n",
    "char['Ratings'] = char['Ratings'].str.replace(',', '').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping cellar and serving temp and removing missing values from their counterparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = char.drop(['Serving Temperature', 'Cellar Temperature'], axis = 1)\n",
    "char['Serving'] = char['Serving'].fillna(char['Serving'].mean())\n",
    "char['Cellar'] = char['Cellar'].fillna(char['Cellar'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = LabelEncoder()\n",
    "lab.fit(char['Style Name'])\n",
    "char['Style Name'] = lab.fit_transform(char['Style Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = char.drop(['Food Paring', 'Glassware Used'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying PCA and Standard scaler on the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "pca.fit(char)\n",
    "char = pca.fit_transform(char)\n",
    "char = pd.DataFrame(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "std.fit(char)\n",
    "char = std.fit_transform(char)\n",
    "char = pd.DataFrame(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data['Serving Temperature'].str.split('-')\n",
    "char.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char.columns = ['First', 'Second', 'third', 'fourth']\n",
    "#(np.sqrt(char.Fourth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num.ABV=num.ABV.fillna(num.ABV.mean())\n",
    "num = num.drop(['Score'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = StandardScaler()\n",
    "st.fit(num)\n",
    "num = st.fit_transform(num)\n",
    "num = pd.DataFrame(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num.columns = ['ABV', 'Brewing', 'Beer Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnum = test_data._get_numeric_data()\n",
    "nchar = test_data.select_dtypes(include = ['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nilu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\nilu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\nilu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "nchar['Serving'] = nchar['Serving Temperature'].str.split('-', expand =True).astype(float).mean(axis=1)\n",
    "nchar['Cellar'] = nchar['Cellar Temperature'].str.split('-', expand =True).astype(float).mean(axis= 1)\n",
    "nchar['Ratings'] = nchar['Ratings'].str.replace(',', '').astype(float)\n",
    "\n",
    "nchar = nchar.drop(['Serving Temperature', 'Cellar Temperature'], axis = 1)\n",
    "nchar['Serving'] = nchar['Serving'].fillna(nchar['Serving'].mean())\n",
    "nchar['Cellar'] = nchar['Cellar'].fillna(nchar['Cellar'].mean())\n",
    "\n",
    "lab = LabelEncoder()\n",
    "lab.fit(nchar['Style Name'])\n",
    "nchar['Style Name'] = lab.fit_transform(nchar['Style Name'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnum['ABV'] = tnum['ABV'].fillna(tnum['ABV'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnum = tnum.drop(['Score'], axis = 1)\n",
    "nchar = nchar.drop(['Food Paring', 'Glassware Used'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "pca.fit(nchar)\n",
    "nchar = pca.fit_transform(nchar)\n",
    "nchar = pd.DataFrame(nchar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "std.fit(nchar)\n",
    "nchar = std.fit_transform(nchar)\n",
    "nchar = pd.DataFrame(nchar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchar.columns = ['First', 'Second','third', 'fourth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta = StandardScaler()\n",
    "sta.fit(tnum)\n",
    "tnum =  sta.fit_transform(tnum)\n",
    "tnum = pd.DataFrame(tnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnum.columns = ['ABV', 'Brewing', 'Beer Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling a) Train test split b) cross validation using grid search cv and xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = pd.concat([nchar, tnum], axis = 1)\n",
    "X = pd.concat([char, num], axis =1)\n",
    "y = train_data.Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Rating     Style       ABV\n",
      "0 -0.110947 -0.759737 -0.078838\n",
      "1 -0.051205 -0.616109 -0.560714\n",
      "2 -0.121490 -0.436574  0.349495\n",
      "3 -0.114461  2.041008 -0.614255\n",
      "4 -0.103919 -0.616109  0.938453\n",
      "     Rating     Style           ABV\n",
      "0 -0.042985 -0.759716  7.935058e-02\n",
      "1 -0.125382 -0.687903 -4.677466e-01\n",
      "2 -0.117535  1.071514  9.547061e-01\n",
      "3 -0.129306 -0.723810 -1.520929e-13\n",
      "4 -0.125382  0.604730 -1.941980e-01\n"
     ]
    }
   ],
   "source": [
    "print(X_t.head())\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "std.fit(X_t)\n",
    "X_t = std.fit_transform(X_t)\n",
    "X_t = pd.DataFrame(X_t)\n",
    "X_t.columns = ['Rating', 'Style', 'ABV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "std1 = StandardScaler()\n",
    "std1.fit(X)\n",
    "X = std.fit_transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "X.columns = ['Rating', 'Style', 'ABV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = X_t.drop(['Brewing Company', 'Serving', 'Beer Name', 'Cellar'], axis = 1)\n",
    "X = X.drop(['Brewing Company', 'Serving', 'Beer Name', 'Cellar'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = xgb.XGBRegressor()\n",
    "parameters = { #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500] }\n",
    "        \n",
    "model = GridSearchCV(estimator =gbm, param_grid =parameters, cv = 3, scoring = 'neg_mean_squared_error',verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7, 'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 500, 'objective': 'reg:linear'}\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "print(model.best_params_)\n",
    "#print(model.best_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35368013300444495\n"
     ]
    }
   ],
   "source": [
    "model1 = xgb.XGBRegressor(learning_rate = 0.07, max_depth = 5, colsample_bytree = 0.7, min_child_weight = 4, n_estimators = 500,)\n",
    "model1.fit(X_train, y_train)\n",
    "predi = model1.predict(X_test)\n",
    "aa = mean_squared_error(predi, y_test)\n",
    "rmse = np.sqrt(aa)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predi = model1.predict(X_t)\n",
    "predi = pd.DataFrame(predi)\n",
    "predi.to_csv('figo3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nlp on the two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37366931707499446\n"
     ]
    }
   ],
   "source": [
    "mod = RandomForestRegressor(n_estimators = 200)\n",
    "mod.fit(X_train, y_train)\n",
    "pred = mod.predict(X_test)\n",
    "aa = mean_squared_error(pred, y_test)\n",
    "print(np.sqrt(aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12508963648204188\n",
      "0.35368013300444495\n"
     ]
    }
   ],
   "source": [
    "model21 = LinearRegression()\n",
    "model21.fit(X_train, y_train)\n",
    "pe = model.predict(X_test)\n",
    "print(mean_squared_error(pe, y_test))\n",
    "print(np.sqrt(mean_squared_error(pe, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model1.predict(X_t)\n",
    "pred1 = mod.predict(X_t)\n",
    "ped = model21.predict(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = np.array([])\n",
    "for i in range(0, len(pred)):\n",
    "    final_pred = np.append(final_pred, np.mean([pred[i], pred1[i], ped[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = pd.DataFrame(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred.to_csv('win.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
